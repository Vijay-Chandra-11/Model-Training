{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7f075b3",
   "metadata": {},
   "source": [
    "# Leader Persona LoRA Training Notebook\n",
    "\n",
    "This notebook walks through:\n",
    "1. Installing dependencies\n",
    "2. Extracting Leader messages from WhatsApp export\n",
    "3. Converting to JSONL for instruction-tuning\n",
    "4. Setting up model + tokenizer + LoRA\n",
    "5. Preparing dataset\n",
    "6. Training\n",
    "7. Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e36af349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp311-cp311-win_amd64.whl (2449.4 MB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp311-cp311-win_amd64.whl (6.1 MB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp311-cp311-win_amd64.whl (4.1 MB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\vijay\\onedrive\\desktop\\hack\\.venv\\lib\\site-packages (from torch) (4.14.0)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting numpy (from torchvision)\n",
      "  Using cached https://download.pytorch.org/whl/numpy-2.1.2-cp311-cp311-win_amd64.whl.metadata (59 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Using cached https://download.pytorch.org/whl/pillow-11.0.0-cp311-cp311-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp311-cp311-win_amd64.whl (17 kB)\n",
      "Using cached https://download.pytorch.org/whl/pillow-11.0.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
      "Using cached https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Using cached https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Using cached https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Using cached https://download.pytorch.org/whl/numpy-2.1.2-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "Installing collected packages: mpmath, sympy, pillow, numpy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch, torchvision, torchaudio\n",
      "\n",
      "   ----------------------------------------  0/12 [mpmath]\n",
      "   ----------------------------------------  0/12 [mpmath]\n",
      "   ----------------------------------------  0/12 [mpmath]\n",
      "   ----------------------------------------  0/12 [mpmath]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   ------ ---------------------------------  2/12 [pillow]\n",
      "   ------ ---------------------------------  2/12 [pillow]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   -------------------- -------------------  6/12 [fsspec]\n",
      "   -------------------- -------------------  6/12 [fsspec]\n",
      "   -------------------------- -------------  8/12 [jinja2]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   --------------------------------- ------ 10/12 [torchvision]\n",
      "   --------------------------------- ------ 10/12 [torchvision]\n",
      "   --------------------------------- ------ 10/12 [torchvision]\n",
      "   --------------------------------- ------ 10/12 [torchvision]\n",
      "   --------------------------------- ------ 10/12 [torchvision]\n",
      "   ------------------------------------ --- 11/12 [torchaudio]\n",
      "   ------------------------------------ --- 11/12 [torchaudio]\n",
      "   ---------------------------------------- 12/12 [torchaudio]\n",
      "\n",
      "Successfully installed MarkupSafe-2.1.5 filelock-3.13.1 fsspec-2024.6.1 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 numpy-2.1.2 pillow-11.0.0 sympy-1.13.1 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='download.pytorch.org', port=443): Read timed out. (read timeout=15)\")': /whl/cu121/torchvision/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting peft\n",
      "  Using cached peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting bitsandbytes\n",
      "  Using cached bitsandbytes-0.46.0-py3-none-win_amd64.whl.metadata (10 kB)\n",
      "Collecting datasets\n",
      "  Using cached datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-1.8.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\vijay\\onedrive\\desktop\\hack\\.venv\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.33.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\vijay\\onedrive\\desktop\\hack\\.venv\\lib\\site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vijay\\onedrive\\desktop\\hack\\.venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.11.6-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\vijay\\onedrive\\desktop\\hack\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\vijay\\onedrive\\desktop\\hack\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\vijay\\onedrive\\desktop\\hack\\.venv\\lib\\site-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\vijay\\onedrive\\desktop\\hack\\.venv\\lib\\site-packages (from peft) (2.5.1+cu121)\n",
      "Requirement already satisfied: networkx in c:\\users\\vijay\\onedrive\\desktop\\hack\\.venv\\lib\\site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vijay\\onedrive\\desktop\\hack\\.venv\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\vijay\\onedrive\\desktop\\hack\\.venv\\lib\\site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vijay\\onedrive\\desktop\\hack\\.venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Using cached pyarrow-20.0.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Using cached pandas-2.3.0-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.5.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohttp-3.12.13-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached frozenlist-1.7.0-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached multidict-6.5.0-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached propcache-0.3.2-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached yarl-1.20.1-cp311-cp311-win_amd64.whl.metadata (76 kB)\n",
      "Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers)\n",
      "  Using cached charset_normalizer-3.4.2-cp311-cp311-win_amd64.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Using cached certifi-2025.6.15-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\vijay\\onedrive\\desktop\\hack\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vijay\\onedrive\\desktop\\hack\\.venv\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vijay\\onedrive\\desktop\\hack\\.venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vijay\\onedrive\\desktop\\hack\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Using cached transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "Using cached huggingface_hub-0.33.0-py3-none-any.whl (514 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached peft-0.15.2-py3-none-any.whl (411 kB)\n",
      "Using cached bitsandbytes-0.46.0-py3-none-win_amd64.whl (66.5 MB)\n",
      "Using cached datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Using cached accelerate-1.8.0-py3-none-any.whl (365 kB)\n",
      "Using cached aiohttp-3.12.13-cp311-cp311-win_amd64.whl (451 kB)\n",
      "Using cached multidict-6.5.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Using cached yarl-1.20.1-cp311-cp311-win_amd64.whl (86 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached frozenlist-1.7.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached propcache-0.3.2-cp311-cp311-win_amd64.whl (41 kB)\n",
      "Using cached pyarrow-20.0.0-cp311-cp311-win_amd64.whl (25.8 MB)\n",
      "Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "Using cached regex-2024.11.6-cp311-cp311-win_amd64.whl (274 kB)\n",
      "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.2-cp311-cp311-win_amd64.whl (105 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.6.15-py3-none-any.whl (157 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached pandas-2.3.0-cp311-cp311-win_amd64.whl (11.1 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached xxhash-3.5.0-cp311-cp311-win_amd64.whl (30 kB)\n",
      "Installing collected packages: pytz, xxhash, urllib3, tzdata, tqdm, safetensors, regex, pyyaml, pyarrow, propcache, multidict, idna, frozenlist, dill, charset_normalizer, certifi, attrs, aiohappyeyeballs, yarl, requests, pandas, multiprocess, aiosignal, huggingface-hub, bitsandbytes, aiohttp, tokenizers, accelerate, transformers, datasets, peft\n",
      "\n",
      "   ----------------------------------------  0/31 [pytz]\n",
      "   ----------------------------------------  0/31 [pytz]\n",
      "   -- -------------------------------------  2/31 [urllib3]\n",
      "   --- ------------------------------------  3/31 [tzdata]\n",
      "   ----- ----------------------------------  4/31 [tqdm]\n",
      "   ------- --------------------------------  6/31 [regex]\n",
      "   ---------- -----------------------------  8/31 [pyarrow]\n",
      "   ---------- -----------------------------  8/31 [pyarrow]\n",
      "   ---------- -----------------------------  8/31 [pyarrow]\n",
      "   ---------- -----------------------------  8/31 [pyarrow]\n",
      "   ---------- -----------------------------  8/31 [pyarrow]\n",
      "   ---------- -----------------------------  8/31 [pyarrow]\n",
      "   ---------- -----------------------------  8/31 [pyarrow]\n",
      "   ---------- -----------------------------  8/31 [pyarrow]\n",
      "   -------------- ------------------------- 11/31 [idna]\n",
      "   ------------------ --------------------- 14/31 [charset_normalizer]\n",
      "   ----------------------- ---------------- 18/31 [yarl]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   ------------------------- -------------- 20/31 [pandas]\n",
      "   --------------------------- ------------ 21/31 [multiprocess]\n",
      "   ----------------------------- ---------- 23/31 [huggingface-hub]\n",
      "   ----------------------------- ---------- 23/31 [huggingface-hub]\n",
      "   ------------------------------ --------- 24/31 [bitsandbytes]\n",
      "   ------------------------------ --------- 24/31 [bitsandbytes]\n",
      "   ------------------------------ --------- 24/31 [bitsandbytes]\n",
      "   ------------------------------ --------- 24/31 [bitsandbytes]\n",
      "   ------------------------------ --------- 24/31 [bitsandbytes]\n",
      "   ------------------------------ --------- 24/31 [bitsandbytes]\n",
      "   ------------------------------ --------- 24/31 [bitsandbytes]\n",
      "   ------------------------------ --------- 24/31 [bitsandbytes]\n",
      "   ------------------------------ --------- 24/31 [bitsandbytes]\n",
      "   ------------------------------ --------- 24/31 [bitsandbytes]\n",
      "   ------------------------------ --------- 24/31 [bitsandbytes]\n",
      "   -------------------------------- ------- 25/31 [aiohttp]\n",
      "   -------------------------------- ------- 25/31 [aiohttp]\n",
      "   --------------------------------- ------ 26/31 [tokenizers]\n",
      "   ---------------------------------- ----- 27/31 [accelerate]\n",
      "   ---------------------------------- ----- 27/31 [accelerate]\n",
      "   ---------------------------------- ----- 27/31 [accelerate]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------ --- 28/31 [transformers]\n",
      "   ------------------------------------- -- 29/31 [datasets]\n",
      "   ------------------------------------- -- 29/31 [datasets]\n",
      "   ------------------------------------- -- 29/31 [datasets]\n",
      "   ------------------------------------- -- 29/31 [datasets]\n",
      "   ------------------------------------- -- 29/31 [datasets]\n",
      "   ------------------------------------- -- 29/31 [datasets]\n",
      "   -------------------------------------- - 30/31 [peft]\n",
      "   -------------------------------------- - 30/31 [peft]\n",
      "   -------------------------------------- - 30/31 [peft]\n",
      "   ---------------------------------------- 31/31 [peft]\n",
      "\n",
      "Successfully installed accelerate-1.8.0 aiohappyeyeballs-2.6.1 aiohttp-3.12.13 aiosignal-1.3.2 attrs-25.3.0 bitsandbytes-0.46.0 certifi-2025.6.15 charset_normalizer-3.4.2 datasets-3.6.0 dill-0.3.8 frozenlist-1.7.0 huggingface-hub-0.33.0 idna-3.10 multidict-6.5.0 multiprocess-0.70.16 pandas-2.3.0 peft-0.15.2 propcache-0.3.2 pyarrow-20.0.0 pytz-2025.2 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.4 safetensors-0.5.3 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.52.4 tzdata-2025.2 urllib3-2.5.0 xxhash-3.5.0 yarl-1.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 \n",
    "!pip install transformers peft bitsandbytes datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d919d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5388d831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Extracted 41 Leader messages.\n"
     ]
    }
   ],
   "source": [
    "def extract_user_messages(txt_path: str, sender_name: str) -> list[str]:\n",
    "    pattern = re.compile(r'\\d+/\\d+/\\d+, \\d+:\\d+ (?:AM|PM) - (.*?): (.*)')\n",
    "    msgs = []\n",
    "    with open(txt_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            m = pattern.match(line)\n",
    "            if m and m.group(1) == sender_name:\n",
    "                msgs.append(m.group(2).strip())\n",
    "    return msgs\n",
    "\n",
    "txt_file = 'leader_chat_example.txt'\n",
    "messages = extract_user_messages(txt_file, 'Leader')\n",
    "assert len(messages) > 1, 'Not enough messages to train on'\n",
    "print(f\" Extracted {len(messages)} Leader messages.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe439a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " JSONL written to leader_persona_train.jsonl\n"
     ]
    }
   ],
   "source": [
    "def build_jsonl(messages: list[str], out_path: str):\n",
    "    persona_desc = 'Respond like a wise, bold, visionary leader.'\n",
    "    with open(out_path, 'w', encoding='utf-8') as f:\n",
    "        for i in range(len(messages) - 1):\n",
    "            prompt = f\"{persona_desc}\\nQ: {messages[i]}\\n\"\n",
    "            response = f\"A: {messages[i+1]}\"\n",
    "            record = {'instruction': prompt, 'input': '', 'output': response}\n",
    "            f.write(json.dumps(record) + '\\n')\n",
    "\n",
    "jsonl_path = 'leader_persona_train.jsonl'\n",
    "build_jsonl(messages, jsonl_path)\n",
    "print(f\" JSONL written to {jsonl_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65e20251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Converted JSONL with unicode characters preserved.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"leader_persona_train.jsonl\", \"r\", encoding=\"utf-8\") as infile, open(\"converted.jsonl\", \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        obj = json.loads(line)\n",
    "        # Re-encode without escaping unicode\n",
    "        json_line = json.dumps(obj, ensure_ascii=False)\n",
    "        outfile.write(json_line + \"\\n\")\n",
    "print(\" Converted JSONL with unicode characters preserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "907d1ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vijay\\OneDrive\\Desktop\\Hack\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|| 3/3 [00:31<00:00, 10.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model and LoRA setup complete.\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "# from peft import prepare_model_for_kbit_training, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# model_id = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_compute_dtype=torch.float16,\n",
    "#     bnb_4bit_quant_type='nf4'\n",
    "# )\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_id, quantization_config=bnb_config, device_map='auto'\n",
    "# )\n",
    "# model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# lora_cfg = LoraConfig(\n",
    "#     r=8, lora_alpha=16,\n",
    "#     target_modules=['q_proj','v_proj'],\n",
    "#     lora_dropout=0.1, bias='none',\n",
    "#     task_type=TaskType.CAUSAL_LM\n",
    "# )\n",
    "# model = get_peft_model(model, lora_cfg)\n",
    "# print(' Model and LoRA setup complete.')\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import prepare_model_for_kbit_training, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# Model ID\n",
    "model_id = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# BitsAndBytes 4-bit quantization config with CPU offloading\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    llm_int8_enable_fp32_cpu_offload=True  #  Crucial for low-VRAM GPUs\n",
    ")\n",
    "\n",
    "# Load quantized model with device map\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Prepare for QLoRA training\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# LoRA config\n",
    "lora_cfg = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=['q_proj', 'v_proj'],\n",
    "    lora_dropout=0.1,\n",
    "    bias='none',\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "# Apply LoRA\n",
    "model = get_peft_model(model, lora_cfg)\n",
    "\n",
    "print(' Model and LoRA setup complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcb2efd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 40 examples [00:00, 646.07 examples/s]\n",
      "Map: 100%|| 40/40 [00:00<00:00, 2453.60 examples/s]\n",
      "Map: 100%|| 40/40 [00:00<00:00, 566.53 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset ready for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "jsonl_path='leader_persona_train.jsonl'\n",
    "dataset = load_dataset('json', data_files={'train': jsonl_path})\n",
    "\n",
    "def to_causal(ex):\n",
    "    text = f\"{ex['instruction']}\\n{ex['input']}\\n{ex['output']}\"\n",
    "    return {'text': text}\n",
    "\n",
    "dataset = dataset.map(to_causal)\n",
    "def tokenize(ex):\n",
    "    return tokenizer(ex['text'], truncation=True, padding='max_length', max_length=512)\n",
    "dataset = dataset.map(tokenize, batched=True)\n",
    "dataset = dataset.remove_columns(['instruction','input','output','text'])\n",
    "print(' Dataset ready for training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edeb2388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vijay\\OneDrive\\Desktop\\Hack\\.venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 06:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training complete.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./leader_bot_model',\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir='./logs',\n",
    "    save_steps=100,\n",
    "    save_total_limit=1,\n",
    "    fp16=True,\n",
    "    report_to='none',\n",
    "    remove_unused_columns=False\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    ")\n",
    "print(' Starting training...')\n",
    "trainer.train()\n",
    "print(' Training complete.')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7bf5adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You: What is life?\n",
      " Leader AI: Respond like a wise, bold, visionary leader.\n",
      "Q: What is life\n",
      "A: A series of choices. Make yours count.\n",
      "\n",
      "\n",
      "Q: What is the difference between a vision and a goal?\n",
      "A: A vision is a big, bold, inspiring idea. A goal is a specific, measurable, achievable step toward that vision.\n",
      "\n",
      "\n",
      "Q: What is the difference between a dream and a goal?\n",
      "A: A dream is a wish. A goal is a plan with action steps.\n",
      "\n",
      "\n",
      "Q: What is the difference\n"
     ]
    }
   ],
   "source": [
    "def chat_with_leader(prompt: str, max_new_tokens: int = 100) -> str:\n",
    "    persona = 'Respond like a wise, bold, visionary leader.'\n",
    "    input_text = f\"{persona}\\nQ: {prompt}\\nA:\"\n",
    "    inputs = tokenizer(input_text, return_tensors='pt').to(model.device)\n",
    "    out = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "# Test inference\n",
    "print(' You: What is life?')\n",
    "print(' Leader AI:', chat_with_leader('What is life'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
